Notes
14-Nov-2024

SUMMARY

01. correlation_matrix			df.corr()
02. classification_report		from sklearn.metrics import classification_report
03. confusion_matrix			from sklearn.metrics import confusion_matrix
04. cross_validation			from sklearn.model_selection import cross_val_score

from sklearn.model_selection import train_test_split


01. correlation_matrix
df.corr()

Ref
anNotes_08-Nov-2024_02.txt

EDA ModelTraining
Test02.py
Test04.py

GPT
table that shows pair-wise correlation coefficients btwn multiple variables
understand how each variable is related to others in the dataset

- spot redundant features [highly correlated ones] that might not add any new info to the model
- detect multi colinearity which can be problematic for certain models like linear regression

Use seaborn to render heatmap to visualize the correlation matrix to make it
easier to spot high or low correlations

Applications
- exclude features w/ high correlations to avoid redundancy
- relationships may inspire new features
- multicollinearity can destabilize the model in linear regression


02. classification_report
Precision vs. Recall
classification_report(y_test, y_pred)
e.g.
precision    recall  f1-score   support

Ref
anMeet_02_12--Nov-2024.txt

EDA ModelTraining
Test05.py
Test06.py

GPT
Precision + Recall
two key metrics used to evaluate the performance of a classification model
esp. where imbalanced classes or FP or FN have different costs

Precision       positive predictive value
measures how accurate the model's positive predictions are

Recall          sensitivity or true positive rate
measures the model's ability to correctly identify all postive instances in dataset


03. confusion_matrix
anMeet_02_12--Nov-2024

GPT
table used to evaluate performance of a classification model by comparing
predicted labels to actual labels

breakdown of model's performance across different classes helping identify
types of errors and measure key metrics like accuracy precision recall and F1 score

TP  Predict +ve Actual +ve
TN  Predict -ve Actual -ve
FP  Predict +ve Actual -ve      diagnosed cancer but don't have it but have treatment		Type  I error
FN  Predict -ve Actual +ve      not diagnosed cancer but you do have it = game over		    Type II error

High TP + TN    indicate model performs well
High FP         model tendency to predict actual -ve as +ve
High FN         model often misses actual +ve cases


04. confusion_matrix
EDA
Test06.py

GPT
stats technique in ML used to evaluate the performance of a model
divide the data into multiple subsets [folds] and train and test
the model on these subsets [folds] in a systematic way

approach provides a more reliable way to estimate model's performance
compared to a single train-test split

assesses how well a model generalizes unseen data + help avoid overfitting
and supporting model selection

useful when you want reliable estimates w/o holding large portion of data
in a fixed test set


SUMMARY
CSV
Pandas      dataFrame   info about data
Matplot     visualize data
Seaborn     correlation matrix  understand how data is related      df.corr()
sklearn     implement machine learning models
sklearn	    confusion_matrix
sklearn     train_test_split
sklearn     classification_report   precision vs. recall

NOTE
sklearn     library has many algorithms that can be used to train models
xgboost     library ideal for high-performing model for tabular data


METHOD
https://www.kaggle.com/code/shrutimechlearn/step-by-step-diabetes-classification

OSEMN Pipeline
O - Obtaining our data
S - Scrubbing / Cleaning our data
E - Exploring / Visualizing our data will allow us to find patterns and trends
M - Modeling our data will give us our predictive power as a wizard
N - Interpreting our data

Obtain data

Basic EDA and statistical analysis
Following columns or variables have an invalid zero value
Histogram       single value
Scatter plot    compare 2x features to visualize correlation
Heatmap         correlation_matrix  seaborn
- feature selection     correlation helps select only the most relevant features
- feature engineering   create new features based on data patterns
Scale data      StandardScaler      sklearn

Train Test Split and Cross Validation methods
train_test_split
algorithm.fit()

Choose algorithm to train model
- result visualization
- fit
- score
Model Performance Analysis  confusion_matrix
algorithm.predict()

Classification Report       classification_report
ROC - AUC                   sklearn.metrics.roc_curve
algorithm.predict()

Hyper Parameter optimization
new_algo.fit()