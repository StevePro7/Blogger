DiagnosingDiabetes
09-Nov-2024

REMEMBER Supervised Machine Learning
https://www.guru99.com/machine-learning-tutorial.html

Classification  predict discrete value - gender of new customer based existing customer data e.g. classify new customer Male/Female
Regression      predict continuous value estimate price of financial stock with the lowest possible error based on financial inputs


INTRODUCTION
768 records
500 healthy     Outcome=0
268 diabetes    Outcome=1

Ten different algorithms
Most successful
Random Forest algorithm 90.1% accuracy

Decision Tree algorithm

The model is designed with Decision Tree, Artificial Neural Networks, Logistic Regression, Random Forest,
and Naive Bayes algorithms

98.8% accuracy using the AdaBoost classifie
C4.5 decision tree, achieved an accuracy of 73.5% to predict diabetes

89% accuracy for diabetes prediction with the SVM-linear model


Ten machine learning algorithms.
in order of accuracy:

01. Random Forest
02. Gradient Boosting
03. XGB
04. LGBM
05. Decision Tree
06. AdaBoost
07. Support Vector Machine
08. Logistic Regression
09. kNN
10. Naive Bayes algorithms


EXPLORATORY DATA ANALYSIS
analyzing datasets using visual methods to summarise their key features and seeing what the data
can say beyond the task of modelling or hypothesis testing

EDA aims to perform initial investigations on data before formal modelling and graphical representations and
visualizations to discover patterns, review assumptions, and test hypotheses


iMPOSSIBLE values
Glucose, BloodPressure, SkinThickness, Insulin, BMI
include the value 0 which is not possible in practice thus need to be corrected
all impossible values were corrected by replacing them with mean values at the pre-processing stage


DiabetesPedigreeFunction
function that scores the probability of diabetes based on family history
realistic range of 0.08 to 2.42

Outcome = target
0   represents healthy people
1   represents those with diabetes


Data visualizations
visual representation of quantitative data for communication and analysis

Heatmaps
used to cross-examine multivariate data, show variance between variables,
show whether any variables are similar to each other, and detect whether there
is a correlation between variables

Most variables are more likely to have non-linear relationships

Glucose is the best indicator of diabetes

higher number of Glucose, BMI, Age, Pregnancies and DiabetesPedigreeFunction
means higher number of diabetes patients
i.e.
higher probability of Outcome=1


MATERIALS AND METHODS
modelling process was analyzed and evaluated with various classifier
models, accuracy, precision, recall, and F1 score performance metrics

Pre-processing
steps to transfer raw data into clean + organized dataset
evaluate and improve data quality to allow reliable analysis

Techniques
- min-max
- variance
- deviation
- standardization
- mean scaling
- elimination of missing values in the data set
- outliers were remvoed from the dataset

IMPORTANT
Data containing missing, outlier and not possible value '0' were replaced with mean values


Feature Engineering
task of improving predictive modelling performance by transforming the feature space in a dataset
extract new features for machine learning models from raw data
e.g.
One-Hot Encoding and Robust Scaler methods


The architecture of the proposed model

Random Forest
combines decision trees and bagging methods
flexible machine learning method used for regression or classification problems
combines a large number of decision trees to obtain more accurate prediction

Gradient Boosting
used for regression or classification problems
each tree is grown using information from previously grown trees

XGB [eXtremem Gradient Boosting]
efficient optimization of the Gradient Boosting technique
approach to find the best decision tree model to achieve higher speed and better performance

LGBM
Lightly Gradient Boosting Machine
decision tree approach with low memory consumption and providing high accuracy
model uses a histogram-based algorithm on high dimensional data to
speed up the computation time and avoid overloading the prediction system

Decision Tree
data is continuously divided according to a certain parameter
used to divide a data set into smaller clusters by applying rules
nodes   where data is divided
leaves  represent decisions
tree structure used is easy to understand and interpret as it can be visualized

AdaBoost
combines many relatively weak and erroneous rules to create an accurate prediction rule

Support Vector Machine [SVM]
high accuracy machine learning method used for classification
SVM is divided into two as linear or nonlinear via decision line
decision function obtained from the training data

Logistic Regression
classification algorithm to analyze dataset
determines an outcome and has independent variables
used in medicine, biology, and economics

kNN [k Nearest Neighbor]
k value determines the number of elements in the classification
searches for the nearest neighbours in the dataset while estimating

Naive Bayes
Bayes' theorem, used in solving classification problems
probabilistic classifier; that is, it makes predictions based on the probability of an object


IMPLEMENTATION
Train / Test split
75%     train
25%     test

Quality of data greatly influences the prediction result means that
pre-processing plays an important part in the model


Measurement
formulas are shown for the following:
- Accuracy
- Precision
- Recall
- F1-score


RESULT AND DISCUSSION
Receiver Operating Characteristic (ROC) curve
expressed as the ratio of sensitivity to specificity

AUC area under curve
the larget the AUC the better the diagnostic test can discriminate it


CONCLUSION
The estimation accuracy is considered the most important factor in the study
It has been determined that the Random Forest algorithm achieves the best success rate
with a 90.1% correct prediction rate